\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[]{acl}
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{graphicx}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Group 46 Progress Report:\\Phishy Checker: Detecting Phishing Websites Using Machine Learning }


\author{Andre Wu, Garv Rastogi, Victor Yu  \\
  \texttt{\{wua55, rastogig, yuv6\}@mcmaster.ca} }

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
% \begin{abstract}
% \end{abstract}

\section{Introduction}

Phishing websites are a form of cyberattack designed to impersonate legitimate websites and deceive users into leaking sensitive credentials. This is a growing problem, as phishing websites can change their visual appearance rapidly and are now easier than ever to create. Traditional detection systems, which rely on blacklists or manual, rule-based checks, often fail to detect new or slightly modified phishing websites. As a result, machine learning methods have emerged as an effective approach to automate the identification of phishing websites.

The objective of this project is to develop an effective machine learning model capable of classifying a website as legitimate or suspicious for phishing based on features such as URL characteristics, SSL certificate information, domain metadata, and other HTML/JavaScript elements. A secondary goal is to ensure high interpretability of the model’s predictions. Using visualization tools such as SHAP or LIME, we aim to provide transparency in the model’s decision-making process, showing users why a particular site is classified as phishing, thereby increasing awareness and educating users.


\section{Related Work}

Here, talk about the related work you encountered for your approach. Cite at least 5 references. Refer to item 2. No one has done exactly your task? Write about the most similar thing you can find. This should be around 0.25-0.5 pages.

\section{Dataset}

The project uses the \textbf{Phishing Websites Dataset} from the UCI Machine Learning Repository \cite{uci_dataset} with DOI: \texttt{10.24432/C51W2X}. The original authors of this dataset are Rami Mohammad and Lee McCluskey. 

The dataset consists of 30 features and 11,055 instances. The features capture various characteristics of a website, including URL length, SSL certificate status, domain age, and usage of JavaScript pop-ups. The target labels in the original dataset are $\langle -1, 0, +1 \rangle$, representing \textit{Phishy}, \textit{Suspicious}, and \textit{Legitimate}, respectively.  

\subsection{Preprocessing}
Since PyTorch's \texttt{CrossEntropyLoss()} does not accept negative target labels, we remapped the target labels from $\langle -1, 0, +1 \rangle$ to $\langle 0, 1, 2 \rangle$. This ensures compatibility with PyTorch while preserving the original class semantics.

\subsection{Data Splitting}
The dataset is split into training and validation subsets using an 80/20 ratio. The split is randomized to ensure reproducibility. This approach aligns with recent course assignments and supports robust evaluation of model performance.

\subsection{Additional Notes}
As the dataset is publicly available and fully labeled, no manual annotation was necessary. The data has been cleaned and all datapoints are ready for model training. The dataset used in this project is attached to the submission as \texttt{Training Dataset.arff}, which contains the raw dataset processed at runtime.


\section{Features}

Describe any features you used for your model, or how your data was input to your model. Are you doing feature engineering or feature selection? Are you learning embeddings? Is it all part of one neural network? Refer to item 3. This may range from 0.25 pages to 0.5 pages.

\section{Implementation}

\subsection{Choice of Model}
Due to the nature of the task, we decided that a feed-forward neural network (FNN) model is a suitable approach. The input training data features likely have complex and non-linear relationships with the targeted output (phishy or not). A feed-forward neural network can naturally model such non-linear feature interactions through multiple hidden layers with non-linear activation functions. 

The FNN also adapts well to multiclass classification by adjusting the number of output neurons to match the number of prediction classes. Additionally, the model is highly scalable and extendable, as the number of input, hidden, and output neurons can be modified for future experiments.

\subsection{Model Definition}
We implemented the feed-forward neural network using PyTorch due to its simplicity and GPU acceleration. The model architecture is as follows:

\begin{itemize}
    \item \textbf{Input layer:} 30 neurons, corresponding to the 30 numeric input features.
    \item \textbf{First hidden layer:} 32 neurons with ReLU activation to introduce non-linearity:
    \begin{equation}
        f(x) = \max(0, x)
    \end{equation}
    \item \textbf{Second hidden layer:} 16 neurons with ReLU activation.
    \item \textbf{Output layer:} 3 neurons, corresponding to the three target classes (phishy, suspicious, legitimate). The softmax function converts raw output scores into probabilities:
    \begin{equation}
        \text{softmax}(z_i) = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}}
    \end{equation}
\end{itemize}

The softmax operation is internally used by PyTorch’s loss function, which will be discussed in Section~\ref{sec:loss}.

\subsection{Loss Evaluation} \label{sec:loss}
To measure how well the predictions match the true target values, we used \textbf{Cross-Entropy Loss}, which is widely used for classification tasks. For $N$ samples, it is defined as:

\begin{equation}
    \text{Loss} = -\frac{1}{N} \sum_{i=1}^{N} \log \frac{e^{z_{i, y_i}}}{\sum_{j} e^{z_{i,j}}}
\end{equation}

This is implemented in PyTorch via \texttt{nn.CrossEntropyLoss()}.

\subsection{Optimization Technique}
We used \textbf{Mini-batch Stochastic Gradient Descent (SGD)} for optimization, which balances computational efficiency with stable weight updates. The batch size was set to 32. The optimization procedure at each iteration is as follows:

\begin{enumerate}
    \item Select a random mini-batch of 32 samples from the dataset.
    \item Perform forward propagation to compute model predictions.
    \item Compute the loss using \texttt{nn.CrossEntropyLoss()}.
    \item Calculate gradients via backpropagation (\texttt{loss.backward()}).
    \item Update model weights using \texttt{optimizer.step()}.
\end{enumerate}

We initially used a learning rate of 0.02 with 5000 training iterations (epochs). Validation loss began to increase after 3000 iterations, indicating overfitting. After experimentation, we found optimal hyperparameters: a learning rate of 0.01 and 3000 training iterations.

\subsection{Baselines for Comparison}
To evaluate model performance, we used a simple \textbf{majority-vote baseline}, which predicts the most frequent class in the training set. The baseline achieved an accuracy of 56.76\%, which is significantly lower than our model’s validation accuracy of over 90\%. This confirms the practical usefulness of our neural network approach.


\section{Results and Evaluation}

The model is evaluated on the phishing website dataset using standard supervised classification metrics, including Accuracy, Precision, Recall, and F1-score, which provide a comprehensive view of the model’s performance across different aspects of prediction. The dataset was split into training (80\%) and validation (20\%) subsets to ensure unbiased evaluation of generalization performance.

\subsection{Model Performance}

\begin{table}[h!]
\centering
\begin{tabular}{lcc}
\hline
\textbf{Metric} & \textbf{Training} & \textbf{Validation} \\
\hline
Accuracy  & 0.9316 & 0.9240 \\
Precision & 0.9308 & 0.9223 \\
Recall    & 0.9307 & 0.9231 \\
F1-score  & 0.9308 & 0.9227 \\
\hline
\end{tabular}
\caption{Model performance metrics on training and validation datasets.}
\label{tab:model_performance}
\end{table}

These results indicate strong predictive performance, with a minor drop from training to validation, suggesting the model generalizes well without significant overfitting. The loss curves over iterations further confirm this, showing a steady decrease in both training and validation loss, indicating stable convergence.

\begin{figure}[h!]
\centering
\includegraphics[width=0.48\textwidth]{loss_curve.png}
\caption{Training and validation loss curves over iterations.}
\label{fig:loss_curve}
\end{figure}

\subsection{Analysis of Suspicious (0) Flags}

To gain further interpretability, we examined which features contain the 0 value, indicating potentially unsafe or anomalous characteristics in URLs. This analysis helps understand which features might be driving model decisions in identifying phishing websites. The top five features with the highest counts of suspicious flags are:

\begin{itemize}
    \item \textbf{redirect} – 7823 suspicious instances
    \item \textbf{links\_pointing\_to\_page} – 4939 suspicious instances
    \item \textbf{url\_of\_anchor} – 4247 suspicious instances
    \item \textbf{links\_in\_tags} – 3545 suspicious instances
    \item \textbf{having\_sub\_domain} – 2891 suspicious instances
\end{itemize}

\begin{figure}[h!]
\centering
\includegraphics[width=0.48\textwidth]{suspicious_features_barplot.png}
\caption{Top 5 features with highest counts of suspicious (0) flags.}
\label{fig:suspicious_features}
\end{figure}

This shows that features related to URL structure and external link references are often flagged as suspicious. For example, a high number of redirects or anchor links is a known indicator of phishing attempts.

\subsection{Mutual Information Analysis}

To complement the suspicious-flag analysis, we computed the mutual information between each feature and the target label. The results indicate that:

\begin{itemize}
    \item \textbf{sslfinal\_state} (MI = 0.3479)
    \item \textbf{url\_of\_anchor} (MI = 0.3294)
\end{itemize}

are the most informative features, confirming the relevance of the suspicious-flag findings. This alignment reinforces the idea that features reflecting security protocols and link structures are critical for phishing detection.

\begin{figure}[h!]
\centering
\includegraphics[width=0.48\textwidth]{mutual_information_plot.png}
\caption{Mutual information of features with the target label.}
\label{fig:mutual_info}
\end{figure}

\subsection{Observations and Insights}

\begin{itemize}
    \item Features with high counts of suspicious flags often correspond to high mutual information scores, suggesting that these features contribute significantly to model prediction.
    \item The combination of metric evaluation, suspicious-feature analysis, and mutual information provides a holistic understanding of model behavior and feature importance.
\end{itemize}

\section{Feedback and Plans}

The TA recommended implementing at least one additional experiment and adding more graphical analyses to better understand model behavior. Following this feedback, the suspicious-feature experiment was introduced as an additional analysis to enhance interpretability. This approach allows us to identify features that are both frequently flagged as suspicious and highly informative for classification, bridging model predictions with domain knowledge.

\subsection{Planned Next Steps}

\subsubsection{Advanced Feature Importance Experiments}
\begin{itemize}
    \item Combine mutual information and suspicious-flag counts to rank features.
    \item Conduct feature ablation studies, where top features are iteratively removed to observe performance impact. This will clarify which features are truly essential.
\end{itemize}

\subsubsection{Model Enhancements}
\begin{itemize}
    \item Experiment with deeper neural network architectures, including additional hidden layers and neurons.
    \item Introduce regularization techniques, such as L2 weight decay or dropout, to further reduce overfitting risk.
    \item Compare results with other classifiers (Random Forest, XGBoost) for benchmarking.
\end{itemize}

\subsubsection{Enhanced Visualization}
\begin{itemize}
    \item Plot training vs. validation loss curves and metrics over epochs to visually monitor overfitting or underfitting.
    \item Include heatmaps or correlation plots for features flagged as suspicious to identify redundancy or interactions between features.
\end{itemize}

\subsubsection{Hyperparameter Optimization}
\begin{itemize}
    \item Systematically tune learning rates, batch sizes, and optimizer choices to maximize convergence speed and final accuracy.
    \item Employ grid search or Bayesian optimization for efficient exploration of hyperparameter space.
\end{itemize}

\subsection{Overall Assessment}

The current model demonstrates high accuracy and robust generalization, and the suspicious-feature experiment provides actionable interpretability. Moving forward, refining the feature set, experimenting with model architecture, and adding comprehensive visualizations will further strengthen both performance and explainability of the phishing detection system.


% \section{Template Notes}

% You can remove this section or comment it out, as it only contains instructions for how to use this template. You may use subsections in your document as you find appropriate.

% \subsection{Tables and figures}

% See Table~\ref{citation-guide} for an example of a table and its caption.
% See Figure~\ref{fig:experiments} for an example of a figure and its caption.


% \begin{figure}[t]
%   \includegraphics[width=\columnwidth]{example-image-golden}
%   \caption{A figure with a caption that runs for more than one line.
%     Example image is usually available through the \texttt{mwe} package
%     without even mentioning it in the preamble.}
%   \label{fig:experiments}
% \end{figure}

% \begin{figure*}[t]
%   \includegraphics[width=0.48\linewidth]{example-image-a} \hfill
%   \includegraphics[width=0.48\linewidth]{example-image-b}
%   \caption {A minimal working example to demonstrate how to place
%     two images side-by-side.}
% \end{figure*}


% \subsection{Citations}

% \begin{table*}
%   \centering
%   \begin{tabular}{lll}
%     \hline
%     \textbf{Output}           & \textbf{natbib command} & \textbf{ACL only command} \\
%     \hline
%     \citep{Gusfield:97}       & \verb|\citep|           &                           \\
%     \citealp{Gusfield:97}     & \verb|\citealp|         &                           \\
%     \citet{Gusfield:97}       & \verb|\citet|           &                           \\
%     \citeyearpar{Gusfield:97} & \verb|\citeyearpar|     &                           \\
%     \citeposs{Gusfield:97}    &                         & \verb|\citeposs|          \\
%     \hline
%   \end{tabular}
%   \caption{\label{citation-guide}
%     Citation commands supported by the style file.
%   }
% \end{table*}

% Table~\ref{citation-guide} shows the syntax supported by the style files.
% We encourage you to use the natbib styles.
% You can use the command \verb|\citet| (cite in text) to get ``author (year)'' citations, like this citation to a paper by \citet{Gusfield:97}.
% You can use the command \verb|\citep| (cite in parentheses) to get ``(author, year)'' citations \citep{Gusfield:97}.
% You can use the command \verb|\citealp| (alternative cite without parentheses) to get ``author, year'' citations, which is useful for using citations within parentheses (e.g. \citealp{Gusfield:97}).

% \subsection{References}

% \nocite{Ando2005,andrew2007scalable,rasooli-tetrault-2015}

% Many websites where you can find academic papers also allow you to export a bib file for citation or bib formatted entry. Copy this into the \texttt{custom.bib} and you will be able to cite the paper in the \LaTeX{}. You can remove the example entries.

% \subsection{Equations}

% An example equation is shown below:
% \begin{equation}
%   \label{eq:example}
%   A = \pi r^2
% \end{equation}

% Labels for equation numbers, sections, subsections, figures and tables
% are all defined with the \verb|\label{label}| command and cross references
% to them are made with the \verb|\ref{label}| command.
% This an example cross-reference to Equation~\ref{eq:example}. You can also write equations inline, like this: $A=\pi r^2$.


% \section*{Limitations}

\section*{Team Contributions}

\begin{table}[h!]
\centering
\begin{tabular}{l p{5cm}}
\hline
\textbf{Team Member} & \textbf{Contributions} \\
\hline
Victor & Sections 1 (Introduction), 2 (Related Work), 3 (Dataset), References section, LaTeX report formatting \\
\hline
Andre  & Sections 4 (Features), 5 (Implementation), Code readability and comments \\
\hline
Garv   & Sections 6 (Results and Evaluation), 7 (Feedback and Plans), Team contributions section, LaTeX report formatting \\
\hline
\end{tabular}
\caption{Summary of team member contributions.}
\label{tab:team_contributions}
\end{table}


% Bibliography entries for the entire Anthology, followed by custom entries
% \bibliography{custom,anthology-overleaf-1,anthology-overleaf-2}

% Custom bibliography entries only
\bibliography{custom}

% \appendix

% \section{Example Appendix}
% \label{sec:appendix}

% This is an appendix.

\end{document}
